import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Dense,Dropout
from tensorflow.keras import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

def build_model(n_input):
    '''
    Constructing a Keras Model
    Parameters:
    n_input: number of input units
    '''
    # Set the learning rate to 0.0002 and use Adam optimization, as well set beta_1 to 0.5 is the
    # recommendation of training GAN model
    g=tf.keras.models.Sequential()
    g.add(tf.keras.Input(shape=(n_input,)))
    g.add(Dense(256,activation='relu'))
    g.add(Dense(512,activation='relu'))
    g.add(Dense(1024,activation='relu'))
    g.add(Dense(784,activation='sigmoid'))
    g.compile(optimizer=Adam(learning_rate=0.0002,beta_1=0.5),loss='binary_crossentropy')

    d=tf.keras.models.Sequential()
    d.add(tf.keras.Input(784,))
    d.add(Dense(1024,activation='relu'))
    d.add(Dropout(0.3))
    d.add(Dense(512,activation='relu'))
    d.add(Dropout(0.3))
    d.add(Dense(256,activation='relu'))
    d.add(Dropout(0.3))
    d.add(Dense(1,activation='sigmoid'))
    d.compile(optimizer=Adam(learning_rate=0.0002,beta_1=0.5),loss='binary_crossentropy')
    
    d.trainable=False
    gan_input=tf.keras.Input((n_input,))
    hidden=g(gan_input)
    gan_output=d(hidden)
    gan=Model(inputs=gan_input,outputs=gan_output)
    gan.compile(optimizer=Adam(learning_rate=0.0002,beta_1=0.5),loss='binary_crossentropy')

    return g,d,gan

def show_image(g,n_image=10,n_input=100):
    '''
    Show image generated by model
    '''
    noise=np.random.normal(0.0,1.0,size=(n_image,n_input))
    images=g.predict(noise)
    images=images.reshape(n_image,28,28)

    plt.figure(figsize=(12,2))
    for i in range(n_image):
        plt.subplot(1,n_image,i+1)
        plt.imshow(images[i],interpolation='nearest',cmap='gray_r')
        plt.axis('off')
    plt.show()

def train_model(X_train,model,epochs,show_fig=True,batch_size=128,n_input=100):
    '''
    train the ganerator and discriminator
    Parameters:
    X_train: training datasets
    model: include g,d,gan
    epochs: number of epochs
    show_fig: show image when training
    batch_size: batch size
    '''
    g,d,gan=model
    losses={'D':[],'G':[]}
    batch_count=X_train.shape[0]//batch_size
    for epoch in range(1,epochs+1):
        print('Epoch {} ...'.format(epoch),end='')
        index=np.random.permutation(X_train.shape[0])
        for i in range(batch_count):
            
            train_img=X_train[np.random.randint(0, X_train.shape[0], size=batch_size)]
            #Generate noise to generate fake image
            noise=np.random.normal(0.0,1.0,size=(batch_size,n_input))
            gen_img=g.predict(noise)

            X=np.concatenate((train_img,gen_img),axis=0)
            y=np.zeros((2*batch_size,))
            y[:batch_size]=0.9

            #Train discriminator
            d.trainable=True
            d_loss=d.train_on_batch(X,y)

            # Generate noise for training generator
            noise=np.random.normal(0.0,1.0,size=(batch_size,n_input))
            y2=np.ones((batch_size,))
            d.trainable=False
            g_loss=gan.train_on_batch(noise,y2)

        losses['D'].append(d_loss)
        losses['G'].append(g_loss)
        print('Generator loss: {}   '.format(losses['G'][epoch-1]),end='')
        print('Discriminator loss:{}'.format(losses['D'][epoch-1]))
        if(show_fig):
            if(epoch==1 or epoch%20==0):
                show_image(g,n_input=n_input)
    return losses,(g,d,gan)
